{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oo_SkUhA0h5"
   },
   "outputs": [],
   "source": [
    "# ---               ---\n",
    "# --- Repo settings ---\n",
    "# ---               ---\n",
    "REPO_URL = \"https://github.com/cecat/breakout-scheduler.git\"\n",
    "BRANCH   = \"main\"\n",
    "REPO_DIR = \"/content/breakout-scheduler\"\n",
    "\n",
    "# --- Inputs: public Google Sheets (CSV export) ---\n",
    "# Working Groups:\n",
    "WG_SHEET_URL  = \"https://docs.google.com/spreadsheets/d/1TkcC0WdcQzhvJSfLllqxNTuagQfbIE4tvfXvoVRlNbo/edit?usp=sharing\"\n",
    "# BOFs:\n",
    "BOF_SHEET_URL = \"https://docs.google.com/spreadsheets/d/1zZJMWT8BlVvDzvyYHE16BYDXjtB-8DaNWh1u_QlnuuU/edit?resourcekey=&gid=1791423820#gid=1791423820\"\n",
    "\n",
    "# --- TEST INPUTS (comment out above assignments before uncommenting these) ---\n",
    "# --- These files will illustrate behavior when the requests oversubscribe the available slots. ---\n",
    "# Working Groups:\n",
    "# WG_SHEET_URL  = \"https://docs.google.com/spreadsheets/d/1_E-J2qkQ7qXxGjUzYems3c3nItQS2mPDrmmAvUxt1hg/edit?usp=sharing\"\n",
    "# BOFs:\n",
    "# BOF_SHEET_URL = \"https://docs.google.com/spreadsheets/d/1dLqDGCisflVqSApQ6Y9EECBiAbPn9Z1KMpTUzqQIimc/edit?usp=share_link\"\n",
    "\n",
    "# Optional: override gid if needed (leave None to auto-detect from URL; default is \"0\")\n",
    "WG_GID  = None\n",
    "BOF_GID = None\n",
    "\n",
    "# --- Runtime paths ---\n",
    "DATA_DIR = \"/content/breakout_inputs\"\n",
    "OUT_DIR  = \"/content/breakout_outputs\"\n",
    "\n",
    "# --- Scheduler options ---\n",
    "PERMUTATIONS      = 5\n",
    "SCHEDULE_BASENAME = \"schedule.csv\"   # scheduler.py will number outputs if PERMUTATIONS > 1\n",
    "CONFIG_PATH       = None             # None => use repo's default config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBJR5nZfBD7s",
    "outputId": "b56c3da5-4cb3-4077-ece6-d691e0b61bd3"
   },
   "outputs": [],
   "source": [
    "# ---                                                         ---\n",
    "# --- Clone Github                                            ---\n",
    "# --- (get the latest python scripts and default config.yaml) ---\n",
    "import os, subprocess\n",
    "\n",
    "if not os.path.isdir(REPO_DIR):\n",
    "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", \"--branch\", BRANCH, REPO_URL, REPO_DIR], check=True)\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "\n",
    "# Make sure code is the latest origin/main each runtime\n",
    "subprocess.run([\"git\", \"fetch\", \"origin\", BRANCH], check=True)\n",
    "subprocess.run([\"git\", \"reset\", \"--hard\", f\"origin/{BRANCH}\"], check=True)\n",
    "\n",
    "print(\"Repo @\", subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-Q0ofsZBSZb"
   },
   "outputs": [],
   "source": [
    "Download the WG and BOF form response CSVs\n",
    "\n",
    "**Note:** This notebook expects *Google Sheets* URLs (from Google Forms response sheets or test sheets). Do **not** use Google Drive file links like `drive.google.com/file/d/...`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fBDEI9YRBYpK",
    "outputId": "7c2106bc-aa17-4640-f3df-8b0486e9c76c"
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "from typing import Optional\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def sheet_to_csv_url(sheet_url: str, gid: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Convert a *Google Sheets* URL to a direct CSV export URL.\n",
    "\n",
    "    Supported inputs:\n",
    "      - https://docs.google.com/spreadsheets/d/<spreadsheet_id>/...#gid=<tab_gid>\n",
    "\n",
    "    Not supported (and will raise a clear error):\n",
    "      - Google Drive file links like https://drive.google.com/file/d/<file_id>/view\n",
    "        If you have a CSV file, open/import it in Google Sheets and use the resulting Sheets URL.\n",
    "    \"\"\"\n",
    "    if \"docs.google.com/spreadsheets\" not in sheet_url:\n",
    "        raise ValueError(\n",
    "            \"Please provide a Google *Sheets* URL (docs.google.com/spreadsheets/...), \"\n",
    "            \"not a Google Drive file link (drive.google.com/file/d/...).\\n\"\n",
    "            \"If your test data is a CSV file, open it with Google Sheets (or import it into a Sheet) \"\n",
    "            \"and use that Sheet's share URL instead.\"\n",
    "        )\n",
    "\n",
    "    m = re.search(r\"/spreadsheets/d/([a-zA-Z0-9-_]+)\", sheet_url)\n",
    "    if not m:\n",
    "        raise ValueError(\"Couldn't find /spreadsheets/d/<spreadsheet_id>/ in the Google Sheet URL.\")\n",
    "    sheet_id = m.group(1)\n",
    "\n",
    "    if gid is None:\n",
    "        m2 = re.search(r\"[#&?]gid=([0-9]+)\", sheet_url)\n",
    "        gid = m2.group(1) if m2 else \"0\"\n",
    "\n",
    "    return f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&gid={gid}\"\n",
    "\n",
    "def download_sheet_csv(sheet_url: str, out_path: str, gid: Optional[str] = None) -> str:\n",
    "    csv_url = sheet_to_csv_url(sheet_url, gid=gid)\n",
    "    urlretrieve(csv_url, out_path)\n",
    "\n",
    "    # Guardrail: if sharing is wrong, Google often returns HTML instead of CSV\n",
    "    with open(out_path, \"rb\") as f:\n",
    "        head = f.read(200).lower()\n",
    "    if b\"<html\" in head or b\"<!doctype html\" in head:\n",
    "        raise RuntimeError(\n",
    "            \"Download did not look like CSV (got HTML). \"\n",
    "            \"Check the sheet sharing is 'Anyone with the link can view'.\\n\"\n",
    "            f\"URL was: {csv_url}\"\n",
    "        )\n",
    "    return csv_url\n",
    "\n",
    "WG_CSV  = os.path.join(DATA_DIR, \"working_groups.csv\")\n",
    "BOF_CSV = os.path.join(DATA_DIR, \"bofs.csv\")\n",
    "\n",
    "wg_export  = download_sheet_csv(WG_SHEET_URL,  WG_CSV,  gid=WG_GID)\n",
    "bof_export = download_sheet_csv(BOF_SHEET_URL, BOF_CSV, gid=BOF_GID)\n",
    "\n",
    "print(\"WG CSV saved to:\", WG_CSV)\n",
    "print(\"BOF CSV saved to:\", BOF_CSV)\n",
    "print(\"WG export URL:\", wg_export)\n",
    "print(\"BOF export URL:\", bof_export)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QPT29muBdQK"
   },
   "source": [
    "Run the Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5UjnyRpBepe",
    "outputId": "9789b169-7f8c-4e70-a2c3-be491d4cd6a5"
   },
   "outputs": [],
   "source": [
    "import os, glob, subprocess, shlex, sys, time\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Clean out old schedules so we don't accidentally summarize stale files\n",
    "for old in glob.glob(os.path.join(OUT_DIR, \"schedule*.csv\")):\n",
    "    try:\n",
    "        os.remove(old)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "schedule_path = os.path.join(OUT_DIR, SCHEDULE_BASENAME)\n",
    "\n",
    "cmd = [\"python\", \"scheduler.py\", \"-w\", WG_CSV, \"-b\", BOF_CSV, \"-s\", schedule_path, \"-p\", str(PERMUTATIONS)]\n",
    "if CONFIG_PATH:\n",
    "    cmd += [\"-c\", CONFIG_PATH]\n",
    "\n",
    "print(\"Running:\", shlex.join(cmd))\n",
    "\n",
    "# Capture output so oversubscription messages are always visible in Colab\n",
    "t0 = time.time()\n",
    "result = subprocess.run(cmd, text=True, capture_output=True)\n",
    "dt = time.time() - t0\n",
    "\n",
    "if result.stdout:\n",
    "    print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(result.stderr, file=sys.stderr)\n",
    "\n",
    "print(f\"(scheduler.py exit code: {result.returncode}, elapsed: {dt:.2f}s)\")\n",
    "\n",
    "schedule_files = sorted(glob.glob(os.path.join(OUT_DIR, \"schedule*.csv\")))\n",
    "if schedule_files:\n",
    "    print(\"Generated schedules:\")\n",
    "    for f in schedule_files:\n",
    "        print(\"  \", f)\n",
    "else:\n",
    "    print(\"No schedule files written.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFLRFHHPBfoz"
   },
   "source": [
    "Run a summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a0e11Q6zBmrb",
    "outputId": "28272226-ef7e-407d-a3fe-a648362fb0fd"
   },
   "outputs": [],
   "source": [
    "import subprocess, os, sys\n",
    "import pandas as pd\n",
    "\n",
    "if not schedule_files:\n",
    "    print(\"No schedules to summarize (likely oversubscription or early exit).\")\n",
    "else:\n",
    "    print(\"\\nSummary report:\\n\")\n",
    "    result = subprocess.run([\"python\", \"schedule_summary.py\", *schedule_files], text=True, capture_output=True)\n",
    "    if result.stdout:\n",
    "        print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(result.stderr, file=sys.stderr)\n",
    "\n",
    "    for f in schedule_files:\n",
    "        print(\"\\n===\", os.path.basename(f), \"===\")\n",
    "        display(pd.read_csv(f))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
